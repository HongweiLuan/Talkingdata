{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " is_attributed\n",
      "\t lgbm_submit2.csv sub-it507.csv\n",
      "\t lgbm_submit3.csv sub_it7.csv\n",
      "\t lgbm_submit2.csv_sub-it507.csv lgbm_submit3.csv_sub_it7.csv\n",
      "\t supple_try.csv lgbm_submit2.csv_sub-it507.csv_lgbm_submit3.csv_sub_it7.csv\n",
      "          click_id  is_attributed\n",
      "0                0       0.100184\n",
      "1                1       0.029167\n",
      "2                2       0.001728\n",
      "3                3       0.023898\n",
      "4                4       0.016909\n",
      "5                5       0.003441\n",
      "6                6       0.014997\n",
      "7                7       0.085643\n",
      "9                8       0.005359\n",
      "8                9       0.082239\n",
      "10              10       0.090264\n",
      "11              11       0.019373\n",
      "12              12       0.005688\n",
      "13              13       0.305827\n",
      "14              14       0.041033\n",
      "15              15       0.003023\n",
      "16              16       0.153958\n",
      "19              17       0.093971\n",
      "20              18       0.017117\n",
      "18              19       0.255761\n",
      "17              20       0.002038\n",
      "21              21       0.214535\n",
      "22              22       0.042809\n",
      "23              23       0.010589\n",
      "24              24       0.000904\n",
      "25              25       0.026928\n",
      "26              26       0.079056\n",
      "27              27       0.033240\n",
      "28              28       0.021582\n",
      "29              29       0.036184\n",
      "...            ...            ...\n",
      "18790438  18790439       0.029276\n",
      "18790440  18790440       0.034787\n",
      "18790441  18790441       0.151871\n",
      "18790442  18790442       0.007108\n",
      "18790443  18790443       0.026161\n",
      "18790444  18790444       0.031966\n",
      "18790445  18790445       0.077947\n",
      "18790446  18790446       0.029185\n",
      "18790447  18790447       0.057661\n",
      "18790448  18790448       0.084814\n",
      "18790449  18790449       0.027904\n",
      "18790450  18790450       0.031543\n",
      "18790451  18790451       0.047226\n",
      "18790452  18790452       0.064081\n",
      "18790453  18790453       0.126186\n",
      "18790455  18790454       0.311132\n",
      "18790454  18790455       0.070851\n",
      "18790456  18790456       0.094233\n",
      "18790457  18790457       0.318412\n",
      "18790458  18790458       0.094087\n",
      "18790459  18790459       0.053574\n",
      "18790460  18790460       0.188374\n",
      "18790462  18790461       0.041671\n",
      "18790461  18790462       0.015917\n",
      "18790463  18790463       0.031090\n",
      "18790464  18790464       0.267738\n",
      "18790465  18790465       0.031207\n",
      "18790467  18790466       0.071402\n",
      "18790466  18790467       0.047383\n",
      "18790468  18790468       0.028797\n",
      "\n",
      "[18790469 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#special thanks to Ryan Epp for his share of this code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Controls weights when combining predictions\n",
    "# 0: equal average of all inputs;\n",
    "# 1: up to 50% of weight going to least correlated input\n",
    "DENSITY_COEFF = 0.1\n",
    "assert DENSITY_COEFF >= 0.0 and DENSITY_COEFF <= 1.0\n",
    "\n",
    "# When merging 2 files with corr > OVER_CORR_CUTOFF\n",
    "# the result's weight is the max instead of the sum of the merged files' weights\n",
    "OVER_CORR_CUTOFF = 0.99\n",
    "assert OVER_CORR_CUTOFF >= 0.0 and OVER_CORR_CUTOFF <= 1.0\n",
    "\n",
    "#Put all the .csv file in ensemble folder\n",
    "INPUT_DIR = 'C:\\\\Users\\\\hluan\\\\Downloads\\\\Kaggle\\\\talk\\\\'\n",
    "\n",
    "def load_submissions():\n",
    "    files = os.listdir(INPUT_DIR)\n",
    "    csv_files = []\n",
    "    for f in files:\n",
    "        if f.endswith(\".csv\"):\n",
    "            csv_files.append(f)\n",
    "    frames = {f:pd.read_csv(INPUT_DIR+f).sort_values('click_id') for f in csv_files}\n",
    "    return frames\n",
    "\n",
    "\n",
    "def get_corr_mat(col,frames):\n",
    "    c = pd.DataFrame()\n",
    "    for name,df in frames.items():\n",
    "        c[name] = df[col]\n",
    "    cor = c.corr()\n",
    "    for name in cor.columns:\n",
    "        cor.set_value(name,name,0.0)\n",
    "    return cor\n",
    "\n",
    "\n",
    "def highest_corr(mat,frames):\n",
    "    n_cor = np.array(mat.values)\n",
    "    corr = np.max(n_cor)\n",
    "    idx = np.unravel_index(np.argmax(n_cor, axis=None), n_cor.shape)\n",
    "    f1 = mat.columns[idx[0]]\n",
    "    f2 = mat.columns[idx[1]]\n",
    "    return corr,f1,f2\n",
    "\n",
    "\n",
    "def get_merge_weights(m1,m2,densities):\n",
    "    d1 = densities[m1]\n",
    "    d2 = densities[m2]\n",
    "    d_tot = d1 + d2\n",
    "    weights1 = 0.5*DENSITY_COEFF + (d1/d_tot)*(1-DENSITY_COEFF)\n",
    "    weights2 = 0.5*DENSITY_COEFF + (d2/d_tot)*(1-DENSITY_COEFF)\n",
    "    return weights1, weights2\n",
    "\n",
    "\n",
    "def ensemble_col(col,frames,densities):\n",
    "    if len(frames) == 1:\n",
    "        _, fr = frames.popitem()\n",
    "        return fr[col]\n",
    "\n",
    "    mat = get_corr_mat(col,frames)\n",
    "    corr,merge1,merge2 = highest_corr(mat,frames)\n",
    "    new_col_name = merge1 + '_' + merge2\n",
    "\n",
    "    w1,w2 = get_merge_weights(merge1,merge2,densities)\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df[col] = (frames[merge1][col]*w1) + (frames[merge2][col]*w2)\n",
    "    del frames[merge1]\n",
    "    del frames[merge2]\n",
    "    frames[new_col_name] = new_df\n",
    "\n",
    "    if corr >= OVER_CORR_CUTOFF:\n",
    "        print('\\t',merge1,merge2,'  (OVER CORR)')\n",
    "        densities[new_col_name] = max(densities[merge1],densities[merge2])\n",
    "    else:\n",
    "        print('\\t',merge1,merge2)\n",
    "        densities[new_col_name] = densities[merge1] + densities[merge2]\n",
    "\n",
    "    del densities[merge1]\n",
    "    del densities[merge2]\n",
    "    #print(densities)\n",
    "    return ensemble_col(col,frames,densities)\n",
    "\n",
    "\n",
    "ens_submission = pd.read_csv('sample_submission.csv').sort_values('click_id')\n",
    "#print(get_corr_mat('toxic',load_submissions()))\n",
    "\n",
    "for col in [\"is_attributed\"]:\n",
    "    frames = load_submissions()\n",
    "    print('\\n\\n',col)\n",
    "    densities = {k:1.0 for k in frames.keys()}\n",
    "    ens_submission[col] = ensemble_col(col,frames,densities)\n",
    "\n",
    "print(ens_submission)\n",
    "ens_submission.to_csv('ensemble_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
