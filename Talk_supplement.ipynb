{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train.csv...\n",
      "Load test.csv...\n",
      "Preprocessing...\n",
      "Adding next_click...\n",
      ">> \n",
      "Extracting nextClick time calculation features...\n",
      "\n",
      ">> Grouping by ['ip', 'app', 'device', 'os', 'channel'], and saving time to nextClick in: ip_app_device_os_channel_nextClick\n",
      ">> Grouping by ['ip', 'os', 'device'], and saving time to nextClick in: ip_os_device_nextClick\n",
      ">> Grouping by ['ip', 'os', 'device', 'app'], and saving time to nextClick in: ip_os_device_app_nextClick\n",
      "Grouping...\n",
      "\n",
      "Counting unqiue  channel  by  ['ip'] ... and saved in ip_by_channel_countuniq\n",
      "\n",
      "Counting unqiue  app  by  ['ip', 'device', 'os'] ... and saved in ip_device_os_by_app_countuniq\n",
      "\n",
      "Counting unqiue  app  by  ['ip'] ... and saved in ip_by_app_countuniq\n",
      "\n",
      "Counting unqiue  os  by  ['ip', 'app'] ... and saved in ip_app_by_os_countuniq\n",
      "\n",
      "Counting unqiue  device  by  ['ip'] ... and saved in ip_by_device_countuniq\n",
      "\n",
      "Counting unqiue  channel  by  ['app'] ... and saved in app_by_channel_countuniq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luanhongwei/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 11400000\n",
      "Valid size: 600000\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luanhongwei/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/luanhongwei/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid's auc: 0.938313\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\tvalid's auc: 0.96411\n",
      "[3]\tvalid's auc: 0.967192\n",
      "[4]\tvalid's auc: 0.96846\n",
      "[5]\tvalid's auc: 0.968129\n",
      "[6]\tvalid's auc: 0.968451\n",
      "[7]\tvalid's auc: 0.969063\n",
      "[8]\tvalid's auc: 0.969823\n",
      "[9]\tvalid's auc: 0.970249\n",
      "[10]\tvalid's auc: 0.970589\n",
      "[11]\tvalid's auc: 0.970934\n",
      "[12]\tvalid's auc: 0.971039\n",
      "[13]\tvalid's auc: 0.971331\n",
      "[14]\tvalid's auc: 0.971451\n",
      "[15]\tvalid's auc: 0.971214\n",
      "[16]\tvalid's auc: 0.971921\n",
      "[17]\tvalid's auc: 0.972052\n",
      "[18]\tvalid's auc: 0.972485\n",
      "[19]\tvalid's auc: 0.972545\n",
      "[20]\tvalid's auc: 0.973474\n",
      "[21]\tvalid's auc: 0.974217\n",
      "[22]\tvalid's auc: 0.974607\n",
      "[23]\tvalid's auc: 0.97506\n",
      "[24]\tvalid's auc: 0.975217\n",
      "[25]\tvalid's auc: 0.975354\n",
      "[26]\tvalid's auc: 0.975193\n",
      "[27]\tvalid's auc: 0.975222\n",
      "[28]\tvalid's auc: 0.975451\n",
      "[29]\tvalid's auc: 0.975873\n",
      "[30]\tvalid's auc: 0.975936\n",
      "[31]\tvalid's auc: 0.975936\n",
      "[32]\tvalid's auc: 0.976187\n",
      "[33]\tvalid's auc: 0.97632\n",
      "[34]\tvalid's auc: 0.976373\n",
      "[35]\tvalid's auc: 0.976842\n",
      "[36]\tvalid's auc: 0.976982\n",
      "[37]\tvalid's auc: 0.977024\n",
      "[38]\tvalid's auc: 0.977024\n",
      "[39]\tvalid's auc: 0.977148\n",
      "[40]\tvalid's auc: 0.97723\n",
      "[41]\tvalid's auc: 0.977446\n",
      "[42]\tvalid's auc: 0.977696\n",
      "[43]\tvalid's auc: 0.977614\n",
      "[44]\tvalid's auc: 0.977836\n",
      "[45]\tvalid's auc: 0.978109\n",
      "[46]\tvalid's auc: 0.978074\n",
      "[47]\tvalid's auc: 0.978161\n",
      "[48]\tvalid's auc: 0.978265\n",
      "[49]\tvalid's auc: 0.978377\n",
      "[50]\tvalid's auc: 0.978392\n",
      "[51]\tvalid's auc: 0.978548\n",
      "[52]\tvalid's auc: 0.978579\n",
      "[53]\tvalid's auc: 0.978627\n",
      "[54]\tvalid's auc: 0.978774\n",
      "[55]\tvalid's auc: 0.978944\n",
      "[56]\tvalid's auc: 0.979148\n",
      "[57]\tvalid's auc: 0.979309\n",
      "[58]\tvalid's auc: 0.979415\n",
      "[59]\tvalid's auc: 0.979291\n",
      "[60]\tvalid's auc: 0.979276\n",
      "[61]\tvalid's auc: 0.979304\n",
      "[62]\tvalid's auc: 0.97943\n",
      "[63]\tvalid's auc: 0.979374\n",
      "[64]\tvalid's auc: 0.979413\n",
      "[65]\tvalid's auc: 0.979467\n",
      "[66]\tvalid's auc: 0.97959\n",
      "[67]\tvalid's auc: 0.979679\n",
      "[68]\tvalid's auc: 0.979748\n",
      "[69]\tvalid's auc: 0.979774\n",
      "[70]\tvalid's auc: 0.979791\n",
      "[71]\tvalid's auc: 0.979754\n",
      "[72]\tvalid's auc: 0.979853\n",
      "[73]\tvalid's auc: 0.979865\n",
      "[74]\tvalid's auc: 0.979979\n",
      "[75]\tvalid's auc: 0.980032\n",
      "[76]\tvalid's auc: 0.980081\n",
      "[77]\tvalid's auc: 0.9801\n",
      "[78]\tvalid's auc: 0.980123\n",
      "[79]\tvalid's auc: 0.980171\n",
      "[80]\tvalid's auc: 0.980205\n",
      "[81]\tvalid's auc: 0.980254\n",
      "[82]\tvalid's auc: 0.980346\n",
      "[83]\tvalid's auc: 0.980346\n",
      "[84]\tvalid's auc: 0.980448\n",
      "[85]\tvalid's auc: 0.980508\n",
      "[86]\tvalid's auc: 0.980572\n",
      "[87]\tvalid's auc: 0.980634\n",
      "[88]\tvalid's auc: 0.980698\n",
      "[89]\tvalid's auc: 0.980689\n",
      "[90]\tvalid's auc: 0.980677\n",
      "[91]\tvalid's auc: 0.980743\n",
      "[92]\tvalid's auc: 0.980775\n",
      "[93]\tvalid's auc: 0.980811\n",
      "[94]\tvalid's auc: 0.980835\n",
      "[95]\tvalid's auc: 0.980822\n",
      "[96]\tvalid's auc: 0.980868\n",
      "[97]\tvalid's auc: 0.980904\n",
      "[98]\tvalid's auc: 0.980965\n",
      "[99]\tvalid's auc: 0.980951\n",
      "[100]\tvalid's auc: 0.980942\n",
      "[101]\tvalid's auc: 0.980966\n",
      "[102]\tvalid's auc: 0.980957\n",
      "[103]\tvalid's auc: 0.980954\n",
      "[104]\tvalid's auc: 0.980982\n",
      "[105]\tvalid's auc: 0.980985\n",
      "[106]\tvalid's auc: 0.98097\n",
      "[107]\tvalid's auc: 0.980961\n",
      "[108]\tvalid's auc: 0.980983\n",
      "[109]\tvalid's auc: 0.980983\n",
      "[110]\tvalid's auc: 0.981019\n",
      "[111]\tvalid's auc: 0.980974\n",
      "[112]\tvalid's auc: 0.980977\n",
      "[113]\tvalid's auc: 0.98098\n",
      "[114]\tvalid's auc: 0.980903\n",
      "[115]\tvalid's auc: 0.980868\n",
      "[116]\tvalid's auc: 0.980892\n",
      "[117]\tvalid's auc: 0.980926\n",
      "[118]\tvalid's auc: 0.980985\n",
      "[119]\tvalid's auc: 0.981003\n",
      "[120]\tvalid's auc: 0.980976\n",
      "[121]\tvalid's auc: 0.980937\n",
      "[122]\tvalid's auc: 0.981004\n",
      "[123]\tvalid's auc: 0.981035\n",
      "[124]\tvalid's auc: 0.98107\n",
      "[125]\tvalid's auc: 0.981065\n",
      "[126]\tvalid's auc: 0.981082\n",
      "[127]\tvalid's auc: 0.98106\n",
      "[128]\tvalid's auc: 0.981093\n",
      "[129]\tvalid's auc: 0.981164\n",
      "[130]\tvalid's auc: 0.981191\n",
      "[131]\tvalid's auc: 0.981194\n",
      "[132]\tvalid's auc: 0.981241\n",
      "[133]\tvalid's auc: 0.981246\n",
      "[134]\tvalid's auc: 0.981301\n",
      "[135]\tvalid's auc: 0.981325\n",
      "[136]\tvalid's auc: 0.981314\n",
      "[137]\tvalid's auc: 0.981348\n",
      "[138]\tvalid's auc: 0.981349\n",
      "[139]\tvalid's auc: 0.981357\n",
      "[140]\tvalid's auc: 0.981343\n",
      "[141]\tvalid's auc: 0.981352\n",
      "[142]\tvalid's auc: 0.981343\n",
      "[143]\tvalid's auc: 0.981347\n",
      "[144]\tvalid's auc: 0.981346\n",
      "[145]\tvalid's auc: 0.981386\n",
      "[146]\tvalid's auc: 0.981441\n",
      "[147]\tvalid's auc: 0.981422\n",
      "[148]\tvalid's auc: 0.981428\n",
      "[149]\tvalid's auc: 0.981459\n",
      "[150]\tvalid's auc: 0.981467\n",
      "[151]\tvalid's auc: 0.981458\n",
      "[152]\tvalid's auc: 0.981452\n",
      "[153]\tvalid's auc: 0.981451\n",
      "[154]\tvalid's auc: 0.98147\n",
      "[155]\tvalid's auc: 0.981471\n",
      "[156]\tvalid's auc: 0.981456\n",
      "[157]\tvalid's auc: 0.981429\n",
      "[158]\tvalid's auc: 0.981469\n",
      "[159]\tvalid's auc: 0.981495\n",
      "[160]\tvalid's auc: 0.981518\n",
      "[161]\tvalid's auc: 0.981449\n",
      "[162]\tvalid's auc: 0.981451\n",
      "[163]\tvalid's auc: 0.981453\n",
      "[164]\tvalid's auc: 0.981471\n",
      "[165]\tvalid's auc: 0.981493\n",
      "[166]\tvalid's auc: 0.981489\n",
      "[167]\tvalid's auc: 0.981494\n",
      "[168]\tvalid's auc: 0.981374\n",
      "[169]\tvalid's auc: 0.981364\n",
      "[170]\tvalid's auc: 0.981369\n",
      "[171]\tvalid's auc: 0.981402\n",
      "[172]\tvalid's auc: 0.981387\n",
      "[173]\tvalid's auc: 0.981392\n",
      "[174]\tvalid's auc: 0.981384\n",
      "[175]\tvalid's auc: 0.981426\n",
      "[176]\tvalid's auc: 0.981446\n",
      "[177]\tvalid's auc: 0.98147\n",
      "[178]\tvalid's auc: 0.981459\n",
      "[179]\tvalid's auc: 0.981473\n",
      "[180]\tvalid's auc: 0.981476\n",
      "[181]\tvalid's auc: 0.981481\n",
      "[182]\tvalid's auc: 0.98142\n",
      "[183]\tvalid's auc: 0.981415\n",
      "[184]\tvalid's auc: 0.981392\n",
      "[185]\tvalid's auc: 0.981363\n",
      "[186]\tvalid's auc: 0.9814\n",
      "[187]\tvalid's auc: 0.981392\n",
      "[188]\tvalid's auc: 0.981386\n",
      "[189]\tvalid's auc: 0.981369\n",
      "[190]\tvalid's auc: 0.981382\n",
      "[191]\tvalid's auc: 0.98139\n",
      "[192]\tvalid's auc: 0.981361\n",
      "[193]\tvalid's auc: 0.981376\n",
      "[194]\tvalid's auc: 0.981386\n",
      "[195]\tvalid's auc: 0.981395\n",
      "[196]\tvalid's auc: 0.981375\n",
      "[197]\tvalid's auc: 0.981396\n",
      "[198]\tvalid's auc: 0.981424\n",
      "[199]\tvalid's auc: 0.981427\n",
      "[200]\tvalid's auc: 0.981424\n",
      "[201]\tvalid's auc: 0.981447\n",
      "[202]\tvalid's auc: 0.98146\n",
      "[203]\tvalid's auc: 0.98146\n",
      "[204]\tvalid's auc: 0.981458\n",
      "[205]\tvalid's auc: 0.98146\n",
      "[206]\tvalid's auc: 0.981483\n",
      "[207]\tvalid's auc: 0.981434\n",
      "[208]\tvalid's auc: 0.981413\n",
      "[209]\tvalid's auc: 0.981449\n",
      "[210]\tvalid's auc: 0.981473\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid's auc: 0.981518\n",
      "\n",
      "Model Info:\n",
      "n_estimators: 160\n",
      "auc: 0.9815184137014391\n",
      "Predicting...\n",
      "Creating: lgbm_submit3.csv\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "\n",
    "max_rounds = 1000\n",
    "early_stop = 50\n",
    "opt_rounds = 680\n",
    "\n",
    "output_file = 'lgbm_submit3.csv'\n",
    "\n",
    "path = \"/home/luanhongwei/talk/\"\n",
    "\n",
    "dtypes = {\n",
    "    'ip'\t\t:'uint32',\n",
    "    'app'\t\t:'uint16',\n",
    "\t'device'\t:'uint16',\n",
    "\t'os'\t\t:'uint16',\n",
    "\t'channel'\t:'uint16',\n",
    "\t'is_attributed'\t:'uint8',\n",
    "\t'click_id'\t:'uint32',\n",
    "\t}\n",
    "\n",
    "print('Loading train.csv...')\n",
    "\n",
    "train_cols = ['ip', 'app', 'device', 'os', 'channel', 'is_attributed', 'click_time']\n",
    "train_df = pd.read_csv(path + 'train.csv', skiprows=range(1,64903891), nrows=120000000, dtype=dtypes, usecols=train_cols)\n",
    "#train_df = pd.read_csv(path + 'train.csv', dtype=dtypes, usecols=train_cols)\n",
    "\n",
    "print('Load test.csv...')\n",
    "test_cols = ['ip', 'app', 'device', 'os', 'click_time', 'channel', 'click_id']\n",
    "test_df = pd.read_csv(path + \"test.csv\", dtype=dtypes, usecols=test_cols)\n",
    "test_supplement_df = pd.read_csv(path + \"test_supplement.csv\", dtype=dtypes, usecols=test_cols)\n",
    "\n",
    "import gc\n",
    "\n",
    "len_train = len(train_df)\n",
    "\n",
    "print('Preprocessing...')\n",
    "\n",
    "most_freq_hours_in_test_data = [4,5,9,10,13,14]\n",
    "least_freq_hours_in_test_data = [6, 11, 15]\n",
    "\n",
    "def add_counts(df, cols):\n",
    "    arr_slice = df[cols].values\n",
    "    unq, unqtags, counts = np.unique(np.ravel_multi_index(arr_slice.T, arr_slice.max(axis=0)+1),\n",
    "                                     return_inverse=True, return_counts=True)\n",
    "    df[\"_\".join(cols)+\"_count\"] = counts[unqtags]\n",
    "\n",
    "def add_next_click(df):\n",
    "    D = 2**26\n",
    "    df['category'] = (df['ip'].astype(str) + \"_\" + df['app'].astype(str) + \"_\" + df['device'].astype(str) \\\n",
    "                      + \"_\" + df['os'].astype(str)).apply(hash) % D\n",
    "    click_buffer = np.full(D, 3000000000, dtype=np.uint32)\n",
    "    df['epochtime'] = df['click_time'].astype(np.int64) // 10 ** 9\n",
    "    next_clicks = []\n",
    "    for category, time in zip(reversed(df['category'].values), reversed(df['epochtime'].values)):\n",
    "        next_clicks.append(click_buffer[category] - time)\n",
    "        click_buffer[category] = time\n",
    "    del click_buffer\n",
    "    df['next_click'] = list(reversed(next_clicks))\n",
    "    df.drop(['category', 'epochtime'], axis=1, inplace=True)\n",
    "    \n",
    "## Below a function is written to extract count feature by aggregating different cols\n",
    "def do_count( df, group_cols, agg_type='uint32', show_max=False, show_agg=True ):\n",
    "    agg_name='{}count'.format('_'.join(group_cols))  \n",
    "    if show_agg:\n",
    "        print( \"\\nAggregating by \", group_cols ,  '... and saved in', agg_name )\n",
    "    gp = df[group_cols][group_cols].groupby(group_cols).size().rename(agg_name).to_frame().reset_index()\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    predictors.append(agg_name)\n",
    "#     print('predictors',predictors)\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "\n",
    "#### Extracting next click feature \n",
    "    ### Taken help from https://www.kaggle.com/nanomathias/feature-engineering-importance-testing\n",
    "    ###Did some Cosmetic changes \n",
    "predictors=[]\n",
    "def do_next_Click( df,agg_suffix='nextClick', agg_type='float32'):\n",
    "    \n",
    "    print(f\">> \\nExtracting {agg_suffix} time calculation features...\\n\")\n",
    "    \n",
    "    GROUP_BY_NEXT_CLICKS = [\n",
    "    \n",
    "    # V1\n",
    "    # {'groupby': ['ip']},\n",
    "    # {'groupby': ['ip', 'app']},\n",
    "    # {'groupby': ['ip', 'channel']},\n",
    "    # {'groupby': ['ip', 'os']},\n",
    "    \n",
    "    # V3\n",
    "    {'groupby': ['ip', 'app', 'device', 'os', 'channel']},\n",
    "    {'groupby': ['ip', 'os', 'device']},\n",
    "    {'groupby': ['ip', 'os', 'device', 'app']}\n",
    "    ]\n",
    "\n",
    "    # Calculate the time to next click for each group\n",
    "    for spec in GROUP_BY_NEXT_CLICKS:\n",
    "    \n",
    "       # Name of new feature\n",
    "        new_feature = '{}_{}'.format('_'.join(spec['groupby']),agg_suffix)    \n",
    "    \n",
    "        # Unique list of features to select\n",
    "        all_features = spec['groupby'] + ['click_time']\n",
    "\n",
    "        # Run calculation\n",
    "        print(f\">> Grouping by {spec['groupby']}, and saving time to {agg_suffix} in: {new_feature}\")\n",
    "        df[new_feature] = (df[all_features].groupby(spec[\n",
    "            'groupby']).click_time.shift(-1) - df.click_time).dt.seconds.astype(agg_type)\n",
    "        \n",
    "        predictors.append(new_feature)\n",
    "        gc.collect()\n",
    "    return (df)\n",
    "\n",
    "def do_prev_Click( df,agg_suffix='prevClick', agg_type='float32'):\n",
    "\n",
    "    print(f\">> \\nExtracting {agg_suffix} time calculation features...\\n\")\n",
    "    \n",
    "    GROUP_BY_NEXT_CLICKS = [\n",
    "    \n",
    "    # V1\n",
    "    # {'groupby': ['ip']},\n",
    "    # {'groupby': ['ip', 'app']},\n",
    "    {'groupby': ['ip', 'channel']},\n",
    "    {'groupby': ['ip', 'os']},\n",
    "    \n",
    "    # V3\n",
    "    #{'groupby': ['ip', 'app', 'device', 'os', 'channel']},\n",
    "    #{'groupby': ['ip', 'os', 'device']},\n",
    "    #{'groupby': ['ip', 'os', 'device', 'app']}\n",
    "    ]\n",
    "\n",
    "    # Calculate the time to next click for each group\n",
    "    for spec in GROUP_BY_NEXT_CLICKS:\n",
    "    \n",
    "       # Name of new feature\n",
    "        new_feature = '{}_{}'.format('_'.join(spec['groupby']),agg_suffix)    \n",
    "    \n",
    "        # Unique list of features to select\n",
    "        all_features = spec['groupby'] + ['click_time']\n",
    "\n",
    "        # Run calculation\n",
    "        print(f\">> Grouping by {spec['groupby']}, and saving time to {agg_suffix} in: {new_feature}\")\n",
    "        df[new_feature] = (df.click_time - df[all_features].groupby(spec[\n",
    "                'groupby']).click_time.shift(+1) ).dt.seconds.astype(agg_type)\n",
    "        \n",
    "        predictors.append(new_feature)\n",
    "        gc.collect()\n",
    "    return (df)    \n",
    "\n",
    "##  Below a function is written to extract unique count feature from different cols\n",
    "def do_countuniq( df, group_cols, counted, agg_type='uint32', show_max=False, show_agg=True ):\n",
    "    agg_name= '{}_by_{}_countuniq'.format(('_'.join(group_cols)),(counted))  \n",
    "    if show_agg:\n",
    "        print( \"\\nCounting unqiue \", counted, \" by \", group_cols ,  '... and saved in', agg_name )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].nunique().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    predictors.append(agg_name)\n",
    "#     print('predictors',predictors)\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "### Below a function is written to extract cumulative count feature  from different cols    \n",
    "def do_cumcount( df, group_cols, counted,agg_type='uint32', show_max=False, show_agg=True ):\n",
    "    agg_name= '{}_by_{}_cumcount'.format(('_'.join(group_cols)),(counted)) \n",
    "    if show_agg:\n",
    "        print( \"\\nCumulative count by \", group_cols , '... and saved in', agg_name  )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].cumcount()\n",
    "    df[agg_name]=gp.values\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    predictors.append(agg_name)\n",
    "#     print('predictors',predictors)\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "### Below a function is written to extract mean feature  from different cols\n",
    "\n",
    "\n",
    "\n",
    "def preproc_data(df):\n",
    "    \n",
    "    #Extrace date info\n",
    "    df['click_time']= pd.to_datetime(df['click_time'])\n",
    "    df['hour'] = df['click_time'].dt.hour.astype('uint8')\n",
    "#     df['day'] = df['click_time'].dt.day.astype('uint8')\n",
    "#     df['wday'] = df['click_time'].dt.dayofweek.astype('uint8')\n",
    "    gc.collect()\n",
    "\n",
    "    #Groups\n",
    "#     df['in_test_hh'] = ( 3\n",
    "# \t    \t\t - 2 * df['hour'].isin( most_freq_hours_in_test_data )\n",
    "# \t\t\t - 1 * df['hour'].isin( least_freq_hours_in_test_data )).astype('uint8')\n",
    "\n",
    "    print('Adding next_click...')\n",
    "#     add_next_click(df)\n",
    "    df = do_next_Click(df)\n",
    "    \n",
    "    print('Grouping...')\n",
    "    \n",
    "    add_counts(df, ['ip'])\n",
    "    add_counts(df, ['os', 'device'])\n",
    "    add_counts(df, ['os', 'app', 'channel'])\n",
    "\n",
    "    add_counts(df, ['ip', 'device'])\n",
    "    add_counts(df, ['app', 'channel'])\n",
    "\n",
    "#     add_counts(df, ['ip', 'wday', 'in_test_hh'])\n",
    "#     add_counts(df, ['ip', 'wday', 'hour'])\n",
    "#     add_counts(df, ['ip', 'os', 'wday', 'hour'])\n",
    "#     add_counts(df, ['ip', 'app', 'wday', 'hour'])\n",
    "#     add_counts(df, ['ip', 'device', 'wday', 'hour'])\n",
    "#     add_counts(df, ['ip', 'app', 'os'])\n",
    "#     add_counts(df, ['wday', 'hour', 'app'])\n",
    "    df = do_countuniq( df, ['ip'], 'channel' ) \n",
    "    gc.collect() \n",
    "    df = do_countuniq( df, ['ip', 'device', 'os'], 'app')\n",
    "    gc.collect()\n",
    "    df = do_countuniq( df, ['ip'], 'app')\n",
    "    gc.collect() \n",
    "    df = do_countuniq( df, ['ip', 'app'], 'os') \n",
    "    gc.collect() \n",
    "    df = do_countuniq( df, ['ip'], 'device')\n",
    "    gc.collect() \n",
    "    df = do_countuniq( df, ['app'], 'channel')\n",
    "    gc.collect()\n",
    "\n",
    "    add_counts(df, ['ip', 'hour']) \n",
    "    gc.collect()\n",
    "    add_counts(df, ['ip', 'os', 'hour']) \n",
    "    gc.collect()\n",
    "    add_counts(df, ['ip', 'app', 'hour']) \n",
    "    add_counts(df, ['ip', 'device', 'hour']) \n",
    "    gc.collect()\n",
    "    add_counts(df, ['ip', 'app', 'os']) \n",
    "    add_counts(df, ['hour', 'app']) \n",
    "    add_counts(df, ['hour', 'channel'])\n",
    "    gc.collect()\n",
    "#     df.drop(['ip', 'click_time'], axis=1, inplace=True )\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "y = train_df.is_attributed.values\n",
    "\n",
    "submit = pd.DataFrame()\n",
    "submit['click_id'] = test_df['click_id']\n",
    "\n",
    "train_len = len(train_df)\n",
    "common_cols = ['ip', 'app', 'device', 'os', 'channel', 'click_time']\n",
    "# train_df = pd.concat([train_df[common_cols], test_df[common_cols]])\n",
    "train_df = pd.concat([train_df[common_cols], test_supplement_df[common_cols]])\n",
    "train_df = preproc_data(train_df)\n",
    "\n",
    "# test_df = train_df.iloc[train_len:]\n",
    "test_supplement_df = train_df.iloc[train_len:]\n",
    "train_df = train_df.iloc[:train_len]\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "metrics = 'auc'\n",
    "lgb_params = {\n",
    "\t'boosting_type': 'gbdt',\n",
    "\t'objective': 'binary',\n",
    "\t'metric': metrics,\n",
    "\t'learning_rate': .1,\n",
    "\t'num_leaves': 7,\n",
    "\t'max_depth': 4,\n",
    "\t'min_child_samples': 100,\n",
    "\t'max_bin': 100,\n",
    "\t'subsample': 0.7,\n",
    "\t'subsample_freq': 1,\n",
    "\t'colsample_bytree': 0.7,\n",
    "\t'min_child_weight': 0,\n",
    "\t'min_split_gain': 0,\n",
    "\t'nthread': 4,\n",
    "\t'verbose': 1,\n",
    "\t'scale_pos_weight': 99.7\n",
    "\t#'scale_pos_weight': 400\n",
    "}\n",
    "\n",
    "target = 'is_attributed'\n",
    "\n",
    "inputs = list(set(train_df.columns) - set([target]) - set(['ip']) - set( ['click_time']))\n",
    "cat_vars = ['app', 'device', 'os', 'channel', 'hour']\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, train_size=.95, shuffle=False)\n",
    "y_train, y_val = train_test_split(y, train_size=.95, shuffle=False)\n",
    "\n",
    "print('Train size:', len(train_df))\n",
    "print('Valid size:', len(val_df))\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print('Training...')\n",
    "\n",
    "num_boost_round=max_rounds\n",
    "early_stopping_rounds=early_stop\n",
    "\n",
    "xgtrain = lgb.Dataset(train_df[inputs].values, label=y_train,\n",
    "\t\t      feature_name=inputs,\n",
    "\t\t      categorical_feature=cat_vars)\n",
    "del train_df\n",
    "gc.collect()\n",
    "\n",
    "xgvalid = lgb.Dataset(val_df[inputs].values, label=y_val,\n",
    "\t\t      feature_name=inputs,\n",
    "\t\t      categorical_feature=cat_vars)\n",
    "del val_df\n",
    "gc.collect()\n",
    "\n",
    "evals_results = {}\n",
    "\n",
    "model = lgb.train(lgb_params,\n",
    "\t\t  xgtrain,\n",
    "\t\t  valid_sets= [xgvalid],\n",
    "\t\t  valid_names=['valid'],\n",
    "\t\t  evals_result=evals_results,\n",
    "\t\t  num_boost_round=num_boost_round,\n",
    "\t\t  early_stopping_rounds=early_stopping_rounds,\n",
    "\t\t  verbose_eval=1,\n",
    "\t\t  feval=None)\n",
    "n_estimators = model.best_iteration\n",
    "\n",
    "print('\\nModel Info:')\n",
    "print('n_estimators:', n_estimators)\n",
    "print(metrics+':', evals_results['valid'][metrics][n_estimators-1])\n",
    "\n",
    "del xgvalid\n",
    "del xgtrain\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "print('Predicting...')\n",
    "submit['is_attributed'] = model.predict(test_df[inputs],num_iteration=model.best_iteration)\n",
    "test_supplement_df['is_attributed'] = model.predict(test_supplement_df[predictors], num_iteration=model.best_iteration)\n",
    "join_cols = ['ip', 'app', 'device', 'os', 'channel', 'click_time']\n",
    "all_cols = join_cols + ['is_attributed']\n",
    "test_df['click_time'] = pd.to_datetime(test_df['click_time'])\n",
    "test_df = test_df.merge(test_supplement_df[all_cols], how='left', on=join_cols)\n",
    "\n",
    "test_df = test_df.drop_duplicates(subset=['click_id'])\n",
    "\n",
    "print(\"Writing the submission data into a csv file...\")\n",
    "\n",
    "test_df[['click_id', 'is_attributed']].to_csv('subtalk_final.csv', index=False, float_format='%.9f')\n",
    "model.save_model('model_final.txt')\n",
    "# print('Creating:', output_file)\n",
    "# submit.to_csv(output_file, index=False, float_format='%.9f')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>hour</th>\n",
       "      <th>ip_app_device_os_channel_nextClick</th>\n",
       "      <th>ip_os_device_nextClick</th>\n",
       "      <th>ip_os_device_app_nextClick</th>\n",
       "      <th>...</th>\n",
       "      <th>ip_app_by_os_countuniq</th>\n",
       "      <th>ip_by_device_countuniq</th>\n",
       "      <th>app_by_channel_countuniq</th>\n",
       "      <th>ip_hour_count</th>\n",
       "      <th>ip_os_hour_count</th>\n",
       "      <th>ip_app_hour_count</th>\n",
       "      <th>ip_device_hour_count</th>\n",
       "      <th>ip_app_os_count</th>\n",
       "      <th>hour_app_count</th>\n",
       "      <th>hour_channel_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12000000</th>\n",
       "      <td>5744</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>475418</td>\n",
       "      <td>214877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000001</th>\n",
       "      <td>119901</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>466</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>18377.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>403</td>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "      <td>400</td>\n",
       "      <td>6</td>\n",
       "      <td>475418</td>\n",
       "      <td>84232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000002</th>\n",
       "      <td>72287</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>128</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>88.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>229</td>\n",
       "      <td>69</td>\n",
       "      <td>13</td>\n",
       "      <td>229</td>\n",
       "      <td>31</td>\n",
       "      <td>77207</td>\n",
       "      <td>83619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000003</th>\n",
       "      <td>78477</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>111</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>3181.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>239</td>\n",
       "      <td>98</td>\n",
       "      <td>10</td>\n",
       "      <td>239</td>\n",
       "      <td>49</td>\n",
       "      <td>209436</td>\n",
       "      <td>14481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000004</th>\n",
       "      <td>123080</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>328</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>396028</td>\n",
       "      <td>38063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ip  app  device  os  channel          click_time  hour  \\\n",
       "12000000    5744    9       1   3      107 2017-11-10 04:00:00     4   \n",
       "12000001  119901    9       1   3      466 2017-11-10 04:00:00     4   \n",
       "12000002   72287   21       1  19      128 2017-11-10 04:00:00     4   \n",
       "12000003   78477   15       1  13      111 2017-11-10 04:00:00     4   \n",
       "12000004  123080   12       1  13      328 2017-11-10 04:00:00     4   \n",
       "\n",
       "          ip_app_device_os_channel_nextClick  ip_os_device_nextClick  \\\n",
       "12000000                                 NaN                     6.0   \n",
       "12000001                             18377.0                    10.0   \n",
       "12000002                                88.0                    66.0   \n",
       "12000003                              3181.0                     5.0   \n",
       "12000004                              1208.0                     4.0   \n",
       "\n",
       "          ip_os_device_app_nextClick         ...          \\\n",
       "12000000                         NaN         ...           \n",
       "12000001                       399.0         ...           \n",
       "12000002                        88.0         ...           \n",
       "12000003                       425.0         ...           \n",
       "12000004                      1208.0         ...           \n",
       "\n",
       "          ip_app_by_os_countuniq  ip_by_device_countuniq  \\\n",
       "12000000                      16                       1   \n",
       "12000001                      29                       8   \n",
       "12000002                      22                       8   \n",
       "12000003                      17                       5   \n",
       "12000004                       9                       3   \n",
       "\n",
       "          app_by_channel_countuniq  ip_hour_count  ip_os_hour_count  \\\n",
       "12000000                        42             34                 3   \n",
       "12000001                        42            403                17   \n",
       "12000002                         7            229                69   \n",
       "12000003                        29            239                98   \n",
       "12000004                        30             60                27   \n",
       "\n",
       "          ip_app_hour_count  ip_device_hour_count  ip_app_os_count  \\\n",
       "12000000                  8                    34                1   \n",
       "12000001                 50                   400                6   \n",
       "12000002                 13                   229               31   \n",
       "12000003                 10                   239               49   \n",
       "12000004                  7                    59                7   \n",
       "\n",
       "          hour_app_count  hour_channel_count  \n",
       "12000000          475418              214877  \n",
       "12000001          475418               84232  \n",
       "12000002           77207               83619  \n",
       "12000003          209436               14481  \n",
       "12000004          396028               38063  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
